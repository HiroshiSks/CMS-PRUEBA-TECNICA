{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2e1506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INICIANDO EXTRACCI√ìN Y NORMALIZACI√ìN DE ARCHIVOS EXCEL...\n",
      "‚úî Leyendo Base de Datos de Transporte P√∫blico - Abril 2021.xlsx | hoja autom√°tica: Veh√≠culos\n",
      "‚úî Leyendo Base de Datos de Transporte P√∫blico - Agosto 2021.xlsx | hoja autom√°tica: Veh√≠culo\n"
     ]
    }
   ],
   "source": [
    "# extraer_vehiculos_corregido.py\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "from rapidfuzz import fuzz\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "# --- 1. Funciones de Normalizaci√≥n ---\n",
    "\n",
    "_re_non_alnum = re.compile(r\"[^0-9a-z]+\")\n",
    "_re_multi_unders = re.compile(r\"_+\")\n",
    "\n",
    "def normalizar_texto(texto: str) -> str:\n",
    "    \"\"\"Normaliza texto: sin acentos, min√∫sculas, underscores limpios.\"\"\"\n",
    "    if not isinstance(texto, str):\n",
    "        # Convierte valores no string a string (√∫til si hay n√∫meros o NaN)\n",
    "        # Esto es vital para que las columnas de n√∫meros/fechas no causen error\n",
    "        return str(texto)\n",
    "\n",
    "    texto = unicodedata.normalize(\"NFKD\", texto)\n",
    "    texto = \"\".join(c for c in texto if not unicodedata.combining(c))\n",
    "    texto = texto.lower()\n",
    "\n",
    "    texto = _re_non_alnum.sub(\"_\", texto)\n",
    "    texto = _re_multi_unders.sub(\"_\", texto)\n",
    "    return texto.strip(\"_\")\n",
    "\n",
    "def normalize_sheet_name(name: str) -> str:\n",
    "    \"\"\"Normaliza y singulariza para evitar 'vehiculos' / 'vehiculo'.\"\"\"\n",
    "    norm = normalizar_texto(name)\n",
    "    # singularizaci√≥n simple\n",
    "    if norm.endswith(\"es\") and len(norm) > 3:\n",
    "        norm = norm[:-2]\n",
    "    elif norm.endswith(\"s\") and len(norm) > 2:\n",
    "        norm = norm[:-1]\n",
    "    return norm\n",
    "\n",
    "# --- 2. Funciones de Extracci√≥n de Metadatos ---\n",
    "\n",
    "MESES = {\n",
    "    \"enero\": 1, \"febrero\": 2, \"marzo\": 3, \"abril\": 4,\n",
    "    \"mayo\": 5, \"junio\": 6, \"julio\": 7, \"agosto\": 8,\n",
    "    \"septiembre\": 9, \"octubre\": 10, \"noviembre\": 11, \"diciembre\": 12\n",
    "}\n",
    "a√±os = ['2025','2024','2023','2022','2021','2020','2019','2018','2017','2016','2015','2014','2013','2012','2011','2010']\n",
    "\n",
    "def extraer_mes_nomb_excel(nombre_archivo: str) -> str | None:\n",
    "    # quitar extensi√≥n\n",
    "    nombre = os.path.splitext(nombre_archivo)[0].lower()\n",
    "\n",
    "    # buscar coincidencia\n",
    "    for mes in MESES:\n",
    "        if mes in nombre:\n",
    "            return mes\n",
    "    return None\n",
    "\n",
    "def extraer_a√±o(nombre_archivo: str) -> str | None:\n",
    "    # quitar extensi√≥n\n",
    "    nombre = os.path.splitext(nombre_archivo)[0].lower()\n",
    "\n",
    "    # buscar coincidencia\n",
    "    for a√±o in a√±os:\n",
    "        if a√±o in nombre:\n",
    "            return a√±o\n",
    "    return None\n",
    "\n",
    "# --- 3. Detecci√≥n de Hojas de Veh√≠culos ---\n",
    "\n",
    "def es_hoja_vehiculo(sheet_name: str) -> bool:\n",
    "    norm = normalize_sheet_name(sheet_name)\n",
    "    tokens = norm.split(\"_\")\n",
    "\n",
    "    # 1) Token empieza con \"veh\" ‚Üí MUY seguro\n",
    "    for t in tokens:\n",
    "        if t.startswith(\"veh\"):\n",
    "            return True\n",
    "\n",
    "    # 2) Excluir expl√≠citamente cosas tipo \"servicio\" / \"servicios\"\n",
    "    if any(t.startswith((\"serv\", \"servi\", \"servic\")) for t in tokens):\n",
    "        return False\n",
    "\n",
    "    # 3) Fuzzy matching seguro contra \"vehiculo\"\n",
    "    score = fuzz.partial_ratio(norm, \"vehiculo\")\n",
    "    if score >= 75:\n",
    "        return True\n",
    "\n",
    "    # 4) Fuzzy por token con longitud m√≠nima\n",
    "    for t in tokens:\n",
    "        if len(t) >= 3:\n",
    "            if fuzz.partial_ratio(t, \"veh\") >= 90:\n",
    "                return True\n",
    "\n",
    "    return False\n",
    "\n",
    "# --- 4. Extracci√≥n Principal ---\n",
    "\n",
    "def leer_excels_vehiculos(root_path: str) -> pd.DataFrame:\n",
    "    todos = []\n",
    "\n",
    "    for year_folder in os.listdir(root_path):\n",
    "        ruta_a√±o = os.path.join(root_path, year_folder)\n",
    "        if not os.path.isdir(ruta_a√±o):\n",
    "            continue\n",
    "\n",
    "        for archivo in os.listdir(ruta_a√±o):\n",
    "            if not archivo.lower().endswith((\".xlsx\", \".xls\", \".xlsm\")):\n",
    "                continue\n",
    "\n",
    "            ruta_file = os.path.join(ruta_a√±o, archivo)\n",
    "\n",
    "            a√±o_det = extraer_a√±o(archivo)\n",
    "            mes_det = extraer_mes_nomb_excel(archivo)\n",
    "\n",
    "            try:\n",
    "                excel = pd.ExcelFile(ruta_file)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error abriendo {archivo}: {e}\")\n",
    "                continue\n",
    "\n",
    "            encontro_hoja = False\n",
    "\n",
    "            for hoja in excel.sheet_names:\n",
    "                if es_hoja_vehiculo(hoja):\n",
    "                    print(f\"‚úî Leyendo {archivo} | hoja autom√°tica: {hoja}\")\n",
    "                    try:\n",
    "                        df = pd.read_excel(ruta_file, sheet_name=hoja)\n",
    "                        \n",
    "                        # ! CORRECCI√ìN CLAVE 1: Normalizar columnas inmediatamente\n",
    "                        df.columns = [normalizar_texto(c) for c in df.columns]\n",
    "                        \n",
    "                        df[\"a√±o_archivo\"] = a√±o_det\n",
    "                        df[\"mes_archivo\"] = mes_det\n",
    "                        df[\"archivo\"] = archivo\n",
    "                        df[\"hoja\"] = hoja\n",
    "                        \n",
    "                        todos.append(df)\n",
    "                        encontro_hoja = True\n",
    "                    except Exception as e:\n",
    "                        print(f\"‚ùå Error leyendo hoja {hoja} en {archivo}: {e}\")\n",
    "                    \n",
    "                    break # Asume que solo quieres una hoja por archivo\n",
    "            \n",
    "            # --- Fallback interactivo si NO encontr√≥ nada ---\n",
    "            if not encontro_hoja:\n",
    "                print(f\"\\n‚ö† No encontr√© ninguna hoja tipo 'vehiculo' en el archivo:\")\n",
    "                print(f\"   ‚Üí {archivo}\")\n",
    "                print(\"   Hojas disponibles:\")\n",
    "\n",
    "                for i, h in enumerate(excel.sheet_names):\n",
    "                    print(f\"   [{i}] {h}\")\n",
    "\n",
    "                try:\n",
    "                    idx = int(input(f\"üëâ Ingresa el n√∫mero de la hoja que quieres usar (o -1 para saltar) opciones{list(range(len(excel.sheet_names)))}: \"))\n",
    "                except:\n",
    "                    print(\"Entrada inv√°lida. Saltando archivo.\")\n",
    "                    continue\n",
    "\n",
    "                if idx == -1:\n",
    "                    print(\"‚è≠ Saltando archivo.\")\n",
    "                    continue\n",
    "                if idx < 0 or idx >= len(excel.sheet_names):\n",
    "                    print(\"‚ùå √çndice fuera de rango. Saltando archivo.\")\n",
    "                    continue\n",
    "\n",
    "                hoja_manual = excel.sheet_names[idx]\n",
    "                print(f\"‚úî Leyendo manualmente: {archivo} | hoja: {hoja_manual}\")\n",
    "\n",
    "                try:\n",
    "                    df = pd.read_excel(ruta_file, sheet_name=hoja_manual)\n",
    "                    \n",
    "                    # ! CORRECCI√ìN CLAVE 1: Normalizar columnas inmediatamente\n",
    "                    df.columns = [normalizar_texto(c) for c in df.columns]\n",
    "                    \n",
    "                    df[\"a√±o_archivo\"] = a√±o_det\n",
    "                    df[\"mes_archivo\"] = mes_det\n",
    "                    df[\"archivo\"] = archivo\n",
    "                    df[\"hoja\"] = hoja_manual\n",
    "                    print(df.isnull().sum())\n",
    "                    todos.append(df)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Error leyendo hoja manual {hoja_manual} en {archivo}: {e}\")\n",
    "                    continue\n",
    "\n",
    "    if todos:\n",
    "        return pd.concat(todos, ignore_index=True)\n",
    "    return pd.DataFrame()\n",
    "\n",
    "# --- 5. Unificaci√≥n de Columnas y Log de Diagn√≥stico ---\n",
    "\n",
    "# Definici√≥n de grupos de columnas para unificaci√≥n\n",
    "# ! REVISA Y COMPLETA ESTA LISTA si encuentras otros nombres de combustible normalizados.\n",
    "column_groups = {\n",
    "    \"tipo_servicio\": [\n",
    "        \"tipo_servicio\", \"tiposervicio\", \"tipo_serviccio\",\n",
    "        \"tipo_servcio\", \"tipo_servicio_\", \"tipo_servicio_1\",\n",
    "        \"tipo_servicio1\"\n",
    "    ],\n",
    "    \"fecha_ingreso_rnt\": [\n",
    "        \"fecha_ingreso_rnt\", \"fecha_ingreso_rntt\", \"fecha_ingreso_rnttt\",\n",
    "        \"fecha_ingreso_rnt_1\", \"fecha_ingreso_rnt1\",\n",
    "        \"fecha_ingreso_rnt_\", \"fecha_ingreso_rnt__\"\n",
    "    ],\n",
    "    \"combustible\": [\n",
    "        \"combustible\", \"tipo_combustible\", \"tipo_combustible_\",\n",
    "        \"tipo_combustible1\", \"combust\", \"combustible_del_vehiculo\" \n",
    "        # A√±ade aqu√≠ otros nombres normalizados que encuentres, ej: 'tipo_fuel'\n",
    "    ],\n",
    "    \"fecha_ingreso\": [\n",
    "        \"fecha_ingreso\", \"fecha_ingreso_servicio\", \"fecha_ingreso1\"\n",
    "    ],\n",
    "    \"ano_fabricacion\": [\n",
    "        \"ano_fabricacion\", \"anofabricacion\", \"a√±o_fabricacion\",\n",
    "        \"ano_fabricacion_\", \"ano_fabricacion1\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "def unificar_columnas(df: pd.DataFrame, groups: dict) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Lista para almacenar las columnas de metadatos (evita dropear metadatos)\n",
    "    meta_cols = [\"a√±o_archivo\", \"mes_archivo\", \"archivo\", \"hoja\"]\n",
    "\n",
    "    for final_col, variantes in groups.items():\n",
    "        # Aseguramos el orden de las columnas existentes (ya normalizadas)\n",
    "        existentes = [c for c in variantes if c in df.columns]\n",
    "        \n",
    "        if not existentes:\n",
    "            # Si no existe ninguna variante, creamos la columna final con nulos (tipo String)\n",
    "            df[final_col] = pd.NA\n",
    "            continue\n",
    "        \n",
    "        # L√≥gica de consolidaci√≥n: Empezamos con la primera variante, y llenamos sus nulos con la siguiente.\n",
    "        df[final_col] = df[existentes[0]]\n",
    "        for col in existentes[1:]:\n",
    "            df[final_col] = df[final_col].fillna(df[col])\n",
    "\n",
    "        # eliminar columnas usadas excepto la final y las de metadatos\n",
    "        to_drop = [c for c in existentes if c != final_col and c not in meta_cols]\n",
    "        df = df.drop(columns=to_drop, errors='ignore')\n",
    "\n",
    "        # ! LOG DE DIAGN√ìSTICO: Muestra el estado de la columna 'combustible'\n",
    "        if final_col == 'combustible':\n",
    "            nulos = df[final_col].isnull().sum()\n",
    "            total = len(df)\n",
    "            porcentaje_nulos = (nulos / total) * 100 if total > 0 else 0\n",
    "            \n",
    "            print(\"=\"*60)\n",
    "            print(f\"‚úÖ CONSOLIDACI√ìN DE COLUMNA: '{final_col}'\")\n",
    "            print(\"=\"*60)\n",
    "            print(f\"   ‚Üí Columnas fuente usadas: {existentes}\")\n",
    "            print(f\"   ‚Üí Total filas: {total}\")\n",
    "            print(f\"   ‚Üí Filas con Nulos: {nulos}\")\n",
    "            print(f\"   ‚Üí Porcentaje de Nulos: {porcentaje_nulos:.2f}%\")\n",
    "            print(\"-\" * 60)\n",
    "            print(f\"   ‚Üí Top 5 Valores despu√©s de la unificaci√≥n (incluyendo nulos):\\n{df[final_col].value_counts(dropna=False).head(5)}\")\n",
    "            print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# --- 6. Conversi√≥n de Tipos y Guardado ---\n",
    "\n",
    "def detect_and_convert_datetime(df: pd.DataFrame, sample_size=100) -> tuple[pd.DataFrame, list]:\n",
    "    \"\"\"Detecta y convierte columnas de objetos que parecen fechas a datetime.\"\"\"\n",
    "    df = df.copy()\n",
    "    obj_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "    date_cols = []\n",
    "    \n",
    "    for col in obj_cols:\n",
    "        nonnull = df[col].dropna()\n",
    "        if nonnull.empty:\n",
    "            continue\n",
    "        sample = nonnull.head(sample_size)\n",
    "        \n",
    "        # Si contiene objetos datetime/Timestamp\n",
    "        if sample.map(lambda x: isinstance(x, (pd.Timestamp, datetime.datetime))).any():\n",
    "            date_cols.append(col)\n",
    "            continue\n",
    "            \n",
    "        # Intentar parsear si parecen cadenas de fecha\n",
    "        parsed = pd.to_datetime(sample, errors=\"coerce\", infer_datetime_format=True)\n",
    "        if parsed.notna().any():\n",
    "            date_cols.append(col)\n",
    "\n",
    "    # Convertir columnas detectadas\n",
    "    for col in date_cols:\n",
    "        df[col] = pd.to_datetime(df[col], errors=\"coerce\", infer_datetime_format=True)\n",
    "\n",
    "    return df, date_cols\n",
    "\n",
    "# --- 7. Ejecuci√≥n Principal ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # ! IMPORTANTE: Define la ruta ra√≠z de tus archivos Excel\n",
    "    root_excels = r\"C:\\\\Users\\\\hiros\\\\\\\\Desktop\\\\\\\\CMS-PRUEBA-TECNICA\\\\\\\\descargas\"\n",
    "    \n",
    "    # 1. Extracci√≥n y normalizaci√≥n\n",
    "    print(\"INICIANDO EXTRACCI√ìN Y NORMALIZACI√ìN DE ARCHIVOS EXCEL...\")\n",
    "    df_vehiculos = leer_excels_vehiculos(root_excels)\n",
    "\n",
    "    if df_vehiculos.empty:\n",
    "        print(\"üõë No se extrajeron datos. Terminando ejecuci√≥n.\")\n",
    "    else:\n",
    "        # 2. Unificaci√≥n de columnas y diagn√≥stico de nulos\n",
    "        print(\"\\nINICIANDO UNIFICACI√ìN DE COLUMNAS (Aqu√≠ ver√°s el LOG de 'combustible')...\")\n",
    "        vehiculos_df = unificar_columnas(df_vehiculos.copy(), column_groups)\n",
    "\n",
    "        # 3. Conversi√≥n de tipos\n",
    "        vehiculos_df, converted_cols = detect_and_convert_datetime(vehiculos_df)\n",
    "        print(\"Columnas convertidas a datetime:\", converted_cols)\n",
    "\n",
    "        # 4. Asegurar tipo string para el resto de objetos\n",
    "        obj_cols = vehiculos_df.select_dtypes(include=[\"object\"]).columns\n",
    "        if len(obj_cols) > 0:\n",
    "            vehiculos_df[obj_cols] = vehiculos_df[obj_cols].astype(\"string\")\n",
    "\n",
    "        # 5. Ordenar columnas (adaptado a los nuevos nombres)\n",
    "        column_order = [\n",
    "            \"folio\", \"region\", \"ppu\", \"linea\", \"marca\", \"modelo\",\n",
    "            \"ano_fabricacion\", \"capacidad\", \"tipo_servicio\", \"combustible\",\n",
    "            \"fecha_ingreso\", \"fecha_ingreso_rnt\", \"mes_archivo\", \"a√±o_archivo\"\n",
    "        ]\n",
    "        \n",
    "        final_cols = [c for c in column_order if c in vehiculos_df.columns]\n",
    "        final_cols += [c for c in vehiculos_df.columns if c not in final_cols]\n",
    "        vehiculos_df = vehiculos_df[final_cols]\n",
    "\n",
    "        # 6. Guardar resultados\n",
    "        print(\"\\nGUARDANDO RESULTADOS...\")\n",
    "        vehiculos_df.to_parquet(\"veh_raw.parquet\", index=False)\n",
    "        vehiculos_df.to_csv(\"vehiculos_extraidos.csv\", index=False)\n",
    "        \n",
    "        print(f\"‚úÖ Proceso terminado. Se extrajeron {len(vehiculos_df)} filas.\")\n",
    "        print(\"Primeras 5 filas del resultado final:\")\n",
    "        print(vehiculos_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
